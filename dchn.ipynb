{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to train a deep convolutional hopfield network to classify MNIST to understand how they work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm going to train a small CNN network using JAX and Equinox and then try to produce alternative code that would implement a hopfield version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import typing as tp\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import equinox as eqx\n",
    "from jaxtyping import PRNGKeyArray\n",
    "\n",
    "class DeepConvNetwork(eqx.Module):\n",
    "    \"\"\"Deep convolutional network with a final linear layer.\n",
    "\n",
    "    Attributes:\n",
    "        num_inputs (int): Number of input features or dimensions.\n",
    "        num_outputs (int): Number of output features or classes.\n",
    "        layers (list[eqx.Module]): Convolutional layers with specified channels and downsampling.\n",
    "        last_layer (eqx.nn.Linear): Final linear layer mapping to output dimensions.\n",
    "\n",
    "    Args:\n",
    "        num_inputs (int): Number of input features or dimensions.\n",
    "        num_outputs (int): Number of output features or classes.\n",
    "        channels (list[int], optional): List specifying the number of channels for each convolutional layer. Defaults to [1, 32, 64].\n",
    "        downsample_factor (int, optional): Downsampling factor for the convolutional layers. Defaults to 2.\n",
    "        key (PRNGKeyArray): Random key for initializing the weights of the network.\n",
    "\n",
    "    Example:\n",
    "        >>> import jax\n",
    "        >>> import equinox as eqx\n",
    "        >>> key = jax.random.PRNGKey(42)\n",
    "        >>> model = DeepConvNetwork(num_inputs=128, num_outputs=10, key=key)\n",
    "        >>> x = jax.random.normal(key, (1, 1, 128, 128))  # Example input\n",
    "        >>> output = model(x)\n",
    "        >>> print(output.shape)  # Shape: (10,)\n",
    "    \"\"\"\n",
    "    num_inputs: int\n",
    "    num_outputs: int\n",
    "    layers: tp.List[eqx.Module]\n",
    "    last_layer: eqx.nn.Linear\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        num_inputs: int, \n",
    "        num_outputs: int, \n",
    "        channels: tp.List[int] = [1, 32, 64], \n",
    "        downsample_factor: int = 2, \n",
    "        key: PRNGKeyArray  = None\n",
    "    ):\n",
    "        self.num_inputs = num_inputs\n",
    "        self.num_outputs = num_outputs\n",
    "        \n",
    "        k1, k2 = jax.random.split(key)\n",
    "\n",
    "        self.layers = [\n",
    "                eqx.nn.Conv2d(\n",
    "                    in_channels=channels[0], \n",
    "                    out_channels=channels[1], \n",
    "                    kernel_size=5, \n",
    "                    padding=2, \n",
    "                    stride=downsample_factor, \n",
    "                    key=k1\n",
    "                ),\n",
    "                eqx.nn.Conv2d(\n",
    "                    in_channels=channels[1], \n",
    "                    out_channels=channels[2], \n",
    "                    kernel_size=3, \n",
    "                    padding=1, \n",
    "                    stride=downsample_factor, \n",
    "                    key=k2\n",
    "                )\n",
    "            ]\n",
    "        \n",
    "        self.last_layer = eqx.nn.Linear((num_inputs * channels[-1] // 16), num_outputs, key=key)\n",
    "\n",
    "    def __call__(self, x: jax.Array) -> jax.Array:\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "            x = jax.nn.relu(x)\n",
    "            print(x.shape)\n",
    "\n",
    "        return jax.nn.sigmoid(self.last_layer(jnp.reshape(x, shape=(-1))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the currently implemented version above, we train using SGD methods from the Optax library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "@eqx.filter_jit\n",
    "@eqx.filter_value_and_grad\n",
    "def calc_loss(model, x, y):\n",
    "    pred = jax.vmap(model)(x)\n",
    "    one_hot = jax.nn.one_hot(y, 10)\n",
    "\n",
    "    MSE = jnp.mean((pred - one_hot) ** 2)\n",
    "    # print(MSE)\n",
    "    return MSE\n",
    "    \n",
    "@eqx.filter_jit\n",
    "def step(model, optimizer, opt_state, x, y):\n",
    "    loss, grads = calc_loss(model, x, y)\n",
    "    updates, opt_state = optimizer.update(grads, opt_state, model)\n",
    "    model = eqx.apply_updates(model, updates)\n",
    "    return model, opt_state, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the data to train on \n",
    "\n",
    "import tensorflow \n",
    "#Fetch MNIST dataset from the ~SOURCE~\n",
    "def fetch_MNIST():\n",
    "\n",
    "    (x_train, y_train), (x_test, y_test) = tensorflow.keras.datasets.mnist.load_data()\n",
    "    x_train = jnp.expand_dims(x_train, 1)\n",
    "    x_test = jnp.expand_dims(x_test, 1)\n",
    "    return x_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First batch shape (inputs): (32, 1, 28, 28)\n",
      "Number of labels in the first batch: 32\n",
      "(32, 14, 14)\n",
      "(64, 7, 7)\n",
      "Batch loss: 0.2489\n",
      "Batch loss: 0.2483\n",
      "Batch loss: 0.2479\n",
      "Batch loss: 0.2483\n",
      "Batch loss: 0.2478\n",
      "Batch loss: 0.2474\n",
      "Batch loss: 0.2478\n",
      "Batch loss: 0.2472\n",
      "Batch loss: 0.2461\n",
      "Batch loss: 0.2457\n",
      "Batch loss: 0.2460\n",
      "Batch loss: 0.2455\n",
      "Batch loss: 0.2451\n",
      "Batch loss: 0.2455\n",
      "Batch loss: 0.2448\n",
      "Batch loss: 0.2447\n",
      "Batch loss: 0.2436\n",
      "Batch loss: 0.2433\n",
      "Batch loss: 0.2437\n",
      "Batch loss: 0.2436\n",
      "Batch loss: 0.2429\n",
      "Batch loss: 0.2423\n",
      "Batch loss: 0.2422\n",
      "Batch loss: 0.2418\n",
      "Batch loss: 0.2405\n",
      "Batch loss: 0.2412\n",
      "Batch loss: 0.2403\n",
      "Batch loss: 0.2408\n",
      "Batch loss: 0.2407\n",
      "Batch loss: 0.2400\n",
      "Batch loss: 0.2398\n",
      "Batch loss: 0.2401\n",
      "Batch loss: 0.2400\n",
      "Batch loss: 0.2388\n",
      "Batch loss: 0.2390\n",
      "Batch loss: 0.2396\n",
      "Batch loss: 0.2388\n",
      "Batch loss: 0.2375\n",
      "Batch loss: 0.2376\n",
      "Batch loss: 0.2366\n",
      "Batch loss: 0.2363\n",
      "Batch loss: 0.2364\n",
      "Batch loss: 0.2352\n",
      "Batch loss: 0.2357\n",
      "Batch loss: 0.2358\n",
      "Batch loss: 0.2360\n",
      "Batch loss: 0.2351\n",
      "Batch loss: 0.2356\n",
      "Batch loss: 0.2347\n",
      "Batch loss: 0.2351\n",
      "Batch loss: 0.2347\n",
      "Batch loss: 0.2347\n",
      "Batch loss: 0.2338\n",
      "Batch loss: 0.2333\n",
      "Batch loss: 0.2335\n",
      "Batch loss: 0.2324\n",
      "Batch loss: 0.2326\n",
      "Batch loss: 0.2324\n",
      "Batch loss: 0.2319\n",
      "Batch loss: 0.2309\n",
      "Batch loss: 0.2309\n",
      "Batch loss: 0.2298\n",
      "Batch loss: 0.2292\n",
      "Batch loss: 0.2294\n",
      "Batch loss: 0.2293\n",
      "Batch loss: 0.2290\n",
      "Batch loss: 0.2286\n",
      "Batch loss: 0.2278\n",
      "Batch loss: 0.2285\n",
      "Batch loss: 0.2282\n",
      "Batch loss: 0.2276\n",
      "Batch loss: 0.2269\n",
      "Batch loss: 0.2274\n",
      "Batch loss: 0.2260\n",
      "Batch loss: 0.2254\n",
      "Batch loss: 0.2244\n",
      "Batch loss: 0.2246\n",
      "Batch loss: 0.2237\n",
      "Batch loss: 0.2231\n",
      "Batch loss: 0.2228\n",
      "Batch loss: 0.2227\n",
      "Batch loss: 0.2232\n",
      "Batch loss: 0.2228\n",
      "Batch loss: 0.2218\n",
      "Batch loss: 0.2230\n",
      "Batch loss: 0.2231\n",
      "Batch loss: 0.2223\n",
      "Batch loss: 0.2220\n",
      "Batch loss: 0.2207\n",
      "Batch loss: 0.2190\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[82], line 40\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m batches:\n\u001b[1;32m     39\u001b[0m     x_batch, y_batch \u001b[38;5;241m=\u001b[39m batch\n\u001b[0;32m---> 40\u001b[0m     model, opt_state, loss \u001b[38;5;241m=\u001b[39m \u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_batch\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Update step\u001b[39;00m\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBatch loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "    \u001b[0;31m[... skipping hidden 2 frame]\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/wotts/lib/python3.11/site-packages/equinox/_jit.py:248\u001b[0m, in \u001b[0;36m_JitWrapper._call\u001b[0;34m(self, is_lower, args, kwargs)\u001b[0m\n\u001b[1;32m    244\u001b[0m         marker, _, _ \u001b[38;5;241m=\u001b[39m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cached(\n\u001b[1;32m    245\u001b[0m             dynamic_donate, dynamic_nodonate, static\n\u001b[1;32m    246\u001b[0m         )\n\u001b[1;32m    247\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m jitting:\n\u001b[0;32m--> 248\u001b[0m         \u001b[43mmarker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblock_until_ready\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m JaxRuntimeError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    250\u001b[0m     \u001b[38;5;66;03m# Catch Equinox's runtime errors, and re-raise them with actually useful\u001b[39;00m\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;66;03m# information. (By default XlaRuntimeError produces a lot of terrifying\u001b[39;00m\n\u001b[1;32m    252\u001b[0m     \u001b[38;5;66;03m# but useless information.)\u001b[39;00m\n\u001b[1;32m    253\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    254\u001b[0m         last_msg \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    255\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m last_stack \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;66;03m# callback necessarily executed in the same interpreter as we are in\u001b[39;00m\n\u001b[1;32m    261\u001b[0m         \u001b[38;5;66;03m# here?\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import optax\n",
    "from typing import List, Tuple\n",
    "\n",
    "# Initialize random key\n",
    "key = jax.random.PRNGKey(42)\n",
    "learning_rate = 1e-5\n",
    "batch_size = 32\n",
    "num_epochs = 10\n",
    "\n",
    "# Initialize model\n",
    "model = DeepConvNetwork(num_inputs=784, num_outputs=10, key=key)\n",
    "\n",
    "# Initialize optimizer\n",
    "optimizer = optax.adam(learning_rate)\n",
    "opt_state = optimizer.init(model)\n",
    "\n",
    "# Fetch and preprocess MNIST dataset\n",
    "x_train, y_train = fetch_MNIST()  # Assumes this function fetches training data\n",
    "x_train = jnp.where(x_train > 20, 1, 0)  # Binarize images\n",
    "x_train = jnp.array(x_train, dtype=jnp.float32)  # Convert to float32\n",
    "\n",
    "# Create batches\n",
    "num_samples = x_train.shape[0]\n",
    "batches: List[Tuple[jnp.ndarray, jnp.ndarray]] = [\n",
    "    (x_train[i:i + batch_size], y_train[i:i + batch_size])\n",
    "    for i in range(0, num_samples, batch_size)\n",
    "]\n",
    "\n",
    "# Print batch information for verification\n",
    "print(f\"First batch shape (inputs): {batches[0][0].shape}\")\n",
    "print(f\"Number of labels in the first batch: {len(batches[0][1])}\")\n",
    "\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs): \n",
    "    for batch in batches:\n",
    "        x_batch, y_batch = batch\n",
    "        model, opt_state, loss = step(model, optimizer, opt_state, x_batch, y_batch)  # Update step\n",
    "        print(f\"Batch loss: {loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok now that we have a rough version of a CNN that can do good enough predictions on MNIST, we move onto DCHN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "import typing as tp\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import equinox as eqx\n",
    "from jaxtyping import PRNGKeyArray\n",
    "\n",
    "class DeepEnergyConvNetwork(eqx.Module):\n",
    "    num_inputs: int\n",
    "    num_outputs: int\n",
    "    layers: tp.List[eqx.Module]\n",
    "    def __init__(\n",
    "        self, \n",
    "        num_inputs: int, \n",
    "        num_outputs: int, \n",
    "        key: PRNGKeyArray  = None\n",
    "    ):\n",
    "        self.num_inputs = num_inputs\n",
    "        self.num_outputs = num_outputs\n",
    "        \n",
    "        k1, k2, k3= jax.random.split(key,3)\n",
    "\n",
    "        self.layers = [\n",
    "            eqx.nn.Linear(\n",
    "                784, 4*784, use_bias=False, key=k1\n",
    "            ),\n",
    "                        eqx.nn.Linear(\n",
    "                4*784, 16*784, use_bias=False, key=k2\n",
    "            ),\n",
    "            eqx.nn.Linear(16*784, num_outputs, use_bias=False, key=k3)\n",
    "        ]\n",
    "\n",
    "\n",
    "    @jax.jit\n",
    "    def primitive(self, s: jax.Array) -> jax.Array:\n",
    "        s_0, s_1, s_2, s_3 = jnp.split(s, [784, 784 + 4*784, 784 + 4*784+ 16*784])\n",
    "        energy = 0.5 * jnp.linalg.norm(s)**2\n",
    "        energy -= jnp.sum(jax.nn.tanh(s_1) * self.layers[0](jax.nn.tanh(s_0)))\n",
    "        energy -= jnp.sum(jax.nn.tanh(s_2) * self.layers[1](jax.nn.tanh(s_1)))\n",
    "        energy -= jnp.sum(jax.nn.tanh(s_3) * self.layers[2](jax.nn.tanh(s_2))) \n",
    "        \n",
    "        return energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, s: [4.   2.03]\n",
      "rho_activation: [4.   2.03]\n",
      "s: [3.0359724 1.0659723]\n",
      "Updated energy: 5.176712\n",
      "Energy at new state: 5.1767120361328125\n",
      "========================================\n",
      "rho_activation: Traced<ShapedArray(float32[2])>with<JVPTrace> with\n",
      "  primal = Array([4.  , 2.03], dtype=float32)\n",
      "  tangent = Traced<ShapedArray(float32[2])>with<JaxprTrace> with\n",
      "    pval = (ShapedArray(float32[2]), None)\n",
      "    recipe = LambdaBinding()\n",
      "s: Traced<ShapedArray(float32[2])>with<JVPTrace> with\n",
      "  primal = Array([3.0359724, 1.0659723], dtype=float32)\n",
      "  tangent = Traced<ShapedArray(float32[2])>with<JaxprTrace> with\n",
      "    pval = (ShapedArray(float32[2]), None)\n",
      "    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x137ce67f0>, in_tracers=(Traced<ShapedArray(float32[2]):JaxprTrace>,), out_tracer_refs=[<weakref at 0x137fbe610; to 'JaxprTracer' at 0x137fbe520>], out_avals=[ShapedArray(float32[2])], primitive=pjit, params={'jaxpr': { lambda ; a:f32[2]. let  in (a,) }, 'in_shardings': (UnspecifiedValue,), 'out_shardings': (UnspecifiedValue,), 'in_layouts': (None,), 'out_layouts': (None,), 'resource_env': None, 'donated_invars': (False,), 'name': 'subtract', 'keep_unused': False, 'inline': True, 'compiler_options_kvs': ()}, effects=set(), source_info=<jax._src.source_info_util.SourceInfo object at 0x137fb8700>, ctx=JaxprEqnContext(compute_type=None, threefry_partitionable=False, cur_abstract_mesh=None, xla_metadata={}))\n",
      "Updated energy: Traced<ShapedArray(float32[])>with<JVPTrace> with\n",
      "  primal = Array(5.176712, dtype=float32)\n",
      "  tangent = Traced<ShapedArray(float32[])>with<JaxprTrace> with\n",
      "    pval = (ShapedArray(float32[]), None)\n",
      "    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x137ce6800>, in_tracers=(Traced<ShapedArray(float32[]):JaxprTrace>, Traced<ShapedArray(float32[]):JaxprTrace>), out_tracer_refs=[<weakref at 0x137fcbd80; to 'JaxprTracer' at 0x137fcbd30>], out_avals=[ShapedArray(float32[])], primitive=pjit, params={'jaxpr': { lambda ; a:f32[] b:f32[]. let c:f32[] = mul b a in (c,) }, 'in_shardings': (UnspecifiedValue, UnspecifiedValue), 'out_shardings': (UnspecifiedValue,), 'in_layouts': (None, None), 'out_layouts': (None,), 'resource_env': None, 'donated_invars': (False, False), 'name': 'multiply', 'keep_unused': False, 'inline': True, 'compiler_options_kvs': ()}, effects=set(), source_info=<jax._src.source_info_util.SourceInfo object at 0x137fb90f0>, ctx=JaxprEqnContext(compute_type=None, threefry_partitionable=False, cur_abstract_mesh=None, xla_metadata={}))\n",
      "Iteration 1, s: [0.96402764 0.96402764]\n",
      "rho_activation: [0.96402764 0.96402764]\n",
      "s: [5.9604645e-08 5.9604645e-08]\n",
      "Updated energy: 3.5527135e-15\n",
      "Energy at new state: 3.552713467042264e-15\n",
      "========================================\n",
      "rho_activation: Traced<ShapedArray(float32[2])>with<JVPTrace> with\n",
      "  primal = Array([0.96402764, 0.96402764], dtype=float32)\n",
      "  tangent = Traced<ShapedArray(float32[2])>with<JaxprTrace> with\n",
      "    pval = (ShapedArray(float32[2]), None)\n",
      "    recipe = LambdaBinding()\n",
      "s: Traced<ShapedArray(float32[2])>with<JVPTrace> with\n",
      "  primal = Array([5.9604645e-08, 5.9604645e-08], dtype=float32)\n",
      "  tangent = Traced<ShapedArray(float32[2])>with<JaxprTrace> with\n",
      "    pval = (ShapedArray(float32[2]), None)\n",
      "    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x137ce6740>, in_tracers=(Traced<ShapedArray(float32[2]):JaxprTrace>,), out_tracer_refs=[<weakref at 0x137fcbbf0; to 'JaxprTracer' at 0x137fcb330>], out_avals=[ShapedArray(float32[2])], primitive=pjit, params={'jaxpr': { lambda ; a:f32[2]. let  in (a,) }, 'in_shardings': (UnspecifiedValue,), 'out_shardings': (UnspecifiedValue,), 'in_layouts': (None,), 'out_layouts': (None,), 'resource_env': None, 'donated_invars': (False,), 'name': 'subtract', 'keep_unused': False, 'inline': True, 'compiler_options_kvs': ()}, effects=set(), source_info=<jax._src.source_info_util.SourceInfo object at 0x137fbb040>, ctx=JaxprEqnContext(compute_type=None, threefry_partitionable=False, cur_abstract_mesh=None, xla_metadata={}))\n",
      "Updated energy: Traced<ShapedArray(float32[])>with<JVPTrace> with\n",
      "  primal = Array(3.5527135e-15, dtype=float32)\n",
      "  tangent = Traced<ShapedArray(float32[])>with<JaxprTrace> with\n",
      "    pval = (ShapedArray(float32[]), None)\n",
      "    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x137ce67f0>, in_tracers=(Traced<ShapedArray(float32[]):JaxprTrace>, Traced<ShapedArray(float32[]):JaxprTrace>), out_tracer_refs=[<weakref at 0x137fcbb50; to 'JaxprTracer' at 0x137fcbb00>], out_avals=[ShapedArray(float32[])], primitive=pjit, params={'jaxpr': { lambda ; a:f32[] b:f32[]. let c:f32[] = mul b a in (c,) }, 'in_shardings': (UnspecifiedValue, UnspecifiedValue), 'out_shardings': (UnspecifiedValue,), 'in_layouts': (None, None), 'out_layouts': (None,), 'resource_env': None, 'donated_invars': (False, False), 'name': 'multiply', 'keep_unused': False, 'inline': True, 'compiler_options_kvs': ()}, effects=set(), source_info=<jax._src.source_info_util.SourceInfo object at 0x137fbba00>, ctx=JaxprEqnContext(compute_type=None, threefry_partitionable=False, cur_abstract_mesh=None, xla_metadata={}))\n",
      "Iteration 2, s: [0.9640276 0.9640276]\n",
      "rho_activation: [0.9640276 0.9640276]\n",
      "s: [0. 0.]\n",
      "Updated energy: 0.0\n",
      "Energy at new state: 0.0\n",
      "========================================\n",
      "rho_activation: Traced<ShapedArray(float32[2])>with<JVPTrace> with\n",
      "  primal = Array([0.9640276, 0.9640276], dtype=float32)\n",
      "  tangent = Traced<ShapedArray(float32[2])>with<JaxprTrace> with\n",
      "    pval = (ShapedArray(float32[2]), None)\n",
      "    recipe = LambdaBinding()\n",
      "s: Traced<ShapedArray(float32[2])>with<JVPTrace> with\n",
      "  primal = Array([0., 0.], dtype=float32)\n",
      "  tangent = Traced<ShapedArray(float32[2])>with<JaxprTrace> with\n",
      "    pval = (ShapedArray(float32[2]), None)\n",
      "    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x137ce6650>, in_tracers=(Traced<ShapedArray(float32[2]):JaxprTrace>,), out_tracer_refs=[<weakref at 0x137fcbba0; to 'JaxprTracer' at 0x137fcaa70>], out_avals=[ShapedArray(float32[2])], primitive=pjit, params={'jaxpr': { lambda ; a:f32[2]. let  in (a,) }, 'in_shardings': (UnspecifiedValue,), 'out_shardings': (UnspecifiedValue,), 'in_layouts': (None,), 'out_layouts': (None,), 'resource_env': None, 'donated_invars': (False,), 'name': 'subtract', 'keep_unused': False, 'inline': True, 'compiler_options_kvs': ()}, effects=set(), source_info=<jax._src.source_info_util.SourceInfo object at 0x137feca00>, ctx=JaxprEqnContext(compute_type=None, threefry_partitionable=False, cur_abstract_mesh=None, xla_metadata={}))\n",
      "Updated energy: Traced<ShapedArray(float32[])>with<JVPTrace> with\n",
      "  primal = Array(0., dtype=float32)\n",
      "  tangent = Traced<ShapedArray(float32[])>with<JaxprTrace> with\n",
      "    pval = (ShapedArray(float32[]), None)\n",
      "    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x137ce6740>, in_tracers=(Traced<ShapedArray(float32[]):JaxprTrace>, Traced<ShapedArray(float32[]):JaxprTrace>), out_tracer_refs=[<weakref at 0x137fcb6a0; to 'JaxprTracer' at 0x137fcb8d0>], out_avals=[ShapedArray(float32[])], primitive=pjit, params={'jaxpr': { lambda ; a:f32[] b:f32[]. let c:f32[] = mul b a in (c,) }, 'in_shardings': (UnspecifiedValue, UnspecifiedValue), 'out_shardings': (UnspecifiedValue,), 'in_layouts': (None, None), 'out_layouts': (None,), 'resource_env': None, 'donated_invars': (False, False), 'name': 'multiply', 'keep_unused': False, 'inline': True, 'compiler_options_kvs': ()}, effects=set(), source_info=<jax._src.source_info_util.SourceInfo object at 0x137fed3c0>, ctx=JaxprEqnContext(compute_type=None, threefry_partitionable=False, cur_abstract_mesh=None, xla_metadata={}))\n",
      "Invalid nan value encountered in the output of a C++-jit/pmap function. Calling the de-optimized version.\n"
     ]
    },
    {
     "ename": "FloatingPointError",
     "evalue": "invalid value (nan) encountered in jit(norm). Because jax_config.debug_nans.value and/or config.jax_debug_infs is set, the de-optimized function (i.e., the function as if the `jit` decorator were removed) was called in an attempt to get a more precise error message. However, the de-optimized function did not produce invalid values during its execution. This behavior can result from `jit` optimizations causing the invalid value to be produced. It may also arise from having nan/inf constants as outputs, like `jax.jit(lambda ...: jax.numpy.nan)(...)`. \n\nIt may be possible to avoid the invalid value by removing the `jit` decorator, at the cost of losing optimizations. \n\nIf you see this error, consider opening a bug report at https://github.com/jax-ml/jax.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFloatingPointError\u001b[0m                        Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/wotts/lib/python3.11/site-packages/jax/_src/dispatch.py:317\u001b[0m, in \u001b[0;36mcheck_special\u001b[0;34m(name, bufs)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m buf \u001b[38;5;129;01min\u001b[39;00m bufs:\n\u001b[0;32m--> 317\u001b[0m   \u001b[43m_check_special\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/wotts/lib/python3.11/site-packages/jax/_src/dispatch.py:322\u001b[0m, in \u001b[0;36m_check_special\u001b[0;34m(name, dtype, buf)\u001b[0m\n\u001b[1;32m    321\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mdebug_nans\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;129;01mand\u001b[39;00m np\u001b[38;5;241m.\u001b[39many(np\u001b[38;5;241m.\u001b[39misnan(np\u001b[38;5;241m.\u001b[39masarray(buf))):\n\u001b[0;32m--> 322\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFloatingPointError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minvalid value (nan) encountered in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    323\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mdebug_infs\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;129;01mand\u001b[39;00m np\u001b[38;5;241m.\u001b[39many(np\u001b[38;5;241m.\u001b[39misinf(np\u001b[38;5;241m.\u001b[39masarray(buf))):\n",
      "\u001b[0;31mFloatingPointError\u001b[0m: invalid value (nan) encountered in pjit",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFloatingPointError\u001b[0m                        Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/wotts/lib/python3.11/site-packages/jax/_src/profiler.py:333\u001b[0m, in \u001b[0;36mannotate_function.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m TraceAnnotation(name, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdecorator_kwargs):\n\u001b[0;32m--> 333\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapper\n",
      "File \u001b[0;32m~/miniconda3/envs/wotts/lib/python3.11/site-packages/jax/_src/interpreters/pxla.py:1303\u001b[0m, in \u001b[0;36mExecuteReplicated.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1302\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m arrays \u001b[38;5;129;01min\u001b[39;00m out_arrays:\n\u001b[0;32m-> 1303\u001b[0m   \u001b[43mdispatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_special\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1304\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout_handler(out_arrays)\n",
      "File \u001b[0;32m~/miniconda3/envs/wotts/lib/python3.11/site-packages/jax/_src/dispatch.py:317\u001b[0m, in \u001b[0;36mcheck_special\u001b[0;34m(name, bufs)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m buf \u001b[38;5;129;01min\u001b[39;00m bufs:\n\u001b[0;32m--> 317\u001b[0m   \u001b[43m_check_special\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/wotts/lib/python3.11/site-packages/jax/_src/dispatch.py:322\u001b[0m, in \u001b[0;36m_check_special\u001b[0;34m(name, dtype, buf)\u001b[0m\n\u001b[1;32m    321\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mdebug_nans\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;129;01mand\u001b[39;00m np\u001b[38;5;241m.\u001b[39many(np\u001b[38;5;241m.\u001b[39misnan(np\u001b[38;5;241m.\u001b[39masarray(buf))):\n\u001b[0;32m--> 322\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFloatingPointError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minvalid value (nan) encountered in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    323\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mdebug_infs\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;129;01mand\u001b[39;00m np\u001b[38;5;241m.\u001b[39many(np\u001b[38;5;241m.\u001b[39misinf(np\u001b[38;5;241m.\u001b[39masarray(buf))):\n",
      "\u001b[0;31mFloatingPointError\u001b[0m: invalid value (nan) encountered in jit(norm)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mJaxStackTraceBeforeTransformation\u001b[0m         Traceback (most recent call last)",
      "File \u001b[0;32m<frozen runpy>:198\u001b[0m, in \u001b[0;36m_run_module_as_main\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m<frozen runpy>:88\u001b[0m, in \u001b[0;36m_run_code\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/wotts/lib/python3.11/site-packages/ipykernel_launcher.py:18\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mipykernel\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m kernelapp \u001b[38;5;28;01mas\u001b[39;00m app\n\u001b[0;32m---> 18\u001b[0m app\u001b[38;5;241m.\u001b[39mlaunch_new_instance()\n",
      "File \u001b[0;32m~/miniconda3/envs/wotts/lib/python3.11/site-packages/traitlets/config/application.py:1075\u001b[0m, in \u001b[0;36mlaunch_instance\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1074\u001b[0m app\u001b[38;5;241m.\u001b[39minitialize(argv)\n\u001b[0;32m-> 1075\u001b[0m app\u001b[38;5;241m.\u001b[39mstart()\n",
      "File \u001b[0;32m~/miniconda3/envs/wotts/lib/python3.11/site-packages/ipykernel/kernelapp.py:739\u001b[0m, in \u001b[0;36mstart\u001b[0;34m()\u001b[0m\n\u001b[1;32m    738\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 739\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mio_loop\u001b[38;5;241m.\u001b[39mstart()\n\u001b[1;32m    740\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/wotts/lib/python3.11/site-packages/tornado/platform/asyncio.py:205\u001b[0m, in \u001b[0;36mstart\u001b[0;34m()\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mstart\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 205\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39masyncio_loop\u001b[38;5;241m.\u001b[39mrun_forever()\n",
      "File \u001b[0;32m~/miniconda3/envs/wotts/lib/python3.11/asyncio/base_events.py:608\u001b[0m, in \u001b[0;36mrun_forever\u001b[0;34m()\u001b[0m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 608\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_once()\n\u001b[1;32m    609\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stopping:\n",
      "File \u001b[0;32m~/miniconda3/envs/wotts/lib/python3.11/asyncio/base_events.py:1936\u001b[0m, in \u001b[0;36m_run_once\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1935\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1936\u001b[0m         handle\u001b[38;5;241m.\u001b[39m_run()\n\u001b[1;32m   1937\u001b[0m handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/wotts/lib/python3.11/asyncio/events.py:84\u001b[0m, in \u001b[0;36m_run\u001b[0;34m()\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 84\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_context\u001b[38;5;241m.\u001b[39mrun(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_callback, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_args)\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mSystemExit\u001b[39;00m, \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m):\n",
      "File \u001b[0;32m~/miniconda3/envs/wotts/lib/python3.11/site-packages/ipykernel/kernelbase.py:545\u001b[0m, in \u001b[0;36mdispatch_queue\u001b[0;34m()\u001b[0m\n\u001b[1;32m    544\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 545\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_one()\n\u001b[1;32m    546\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/wotts/lib/python3.11/site-packages/ipykernel/kernelbase.py:534\u001b[0m, in \u001b[0;36mprocess_one\u001b[0;34m()\u001b[0m\n\u001b[1;32m    533\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m--> 534\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m dispatch(\u001b[38;5;241m*\u001b[39margs)\n",
      "File \u001b[0;32m~/miniconda3/envs/wotts/lib/python3.11/site-packages/ipykernel/kernelbase.py:437\u001b[0m, in \u001b[0;36mdispatch_shell\u001b[0;34m()\u001b[0m\n\u001b[1;32m    436\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39misawaitable(result):\n\u001b[0;32m--> 437\u001b[0m         \u001b[38;5;28;01mawait\u001b[39;00m result\n\u001b[1;32m    438\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/wotts/lib/python3.11/site-packages/ipykernel/ipkernel.py:362\u001b[0m, in \u001b[0;36mexecute_request\u001b[0;34m()\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_associate_new_top_level_threads_with(parent_header)\n\u001b[0;32m--> 362\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mexecute_request(stream, ident, parent)\n",
      "File \u001b[0;32m~/miniconda3/envs/wotts/lib/python3.11/site-packages/ipykernel/kernelbase.py:778\u001b[0m, in \u001b[0;36mexecute_request\u001b[0;34m()\u001b[0m\n\u001b[1;32m    777\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39misawaitable(reply_content):\n\u001b[0;32m--> 778\u001b[0m     reply_content \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m reply_content\n\u001b[1;32m    780\u001b[0m \u001b[38;5;66;03m# Flush output before sending the reply.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/wotts/lib/python3.11/site-packages/ipykernel/ipkernel.py:449\u001b[0m, in \u001b[0;36mdo_execute\u001b[0;34m()\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m accepts_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_id\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m--> 449\u001b[0m     res \u001b[38;5;241m=\u001b[39m shell\u001b[38;5;241m.\u001b[39mrun_cell(\n\u001b[1;32m    450\u001b[0m         code,\n\u001b[1;32m    451\u001b[0m         store_history\u001b[38;5;241m=\u001b[39mstore_history,\n\u001b[1;32m    452\u001b[0m         silent\u001b[38;5;241m=\u001b[39msilent,\n\u001b[1;32m    453\u001b[0m         cell_id\u001b[38;5;241m=\u001b[39mcell_id,\n\u001b[1;32m    454\u001b[0m     )\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/wotts/lib/python3.11/site-packages/ipykernel/zmqshell.py:549\u001b[0m, in \u001b[0;36mrun_cell\u001b[0;34m()\u001b[0m\n\u001b[1;32m    548\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_last_traceback \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 549\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrun_cell(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/wotts/lib/python3.11/site-packages/IPython/core/interactiveshell.py:3075\u001b[0m, in \u001b[0;36mrun_cell\u001b[0;34m()\u001b[0m\n\u001b[1;32m   3074\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3075\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_cell(\n\u001b[1;32m   3076\u001b[0m         raw_cell, store_history, silent, shell_futures, cell_id\n\u001b[1;32m   3077\u001b[0m     )\n\u001b[1;32m   3078\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/wotts/lib/python3.11/site-packages/IPython/core/interactiveshell.py:3130\u001b[0m, in \u001b[0;36m_run_cell\u001b[0;34m()\u001b[0m\n\u001b[1;32m   3129\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3130\u001b[0m     result \u001b[38;5;241m=\u001b[39m runner(coro)\n\u001b[1;32m   3131\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/miniconda3/envs/wotts/lib/python3.11/site-packages/IPython/core/async_helpers.py:128\u001b[0m, in \u001b[0;36m_pseudo_sync_runner\u001b[0;34m()\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 128\u001b[0m     coro\u001b[38;5;241m.\u001b[39msend(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m~/miniconda3/envs/wotts/lib/python3.11/site-packages/IPython/core/interactiveshell.py:3334\u001b[0m, in \u001b[0;36mrun_cell_async\u001b[0;34m()\u001b[0m\n\u001b[1;32m   3331\u001b[0m interactivity \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m silent \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mast_node_interactivity\n\u001b[0;32m-> 3334\u001b[0m has_raised \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_ast_nodes(code_ast\u001b[38;5;241m.\u001b[39mbody, cell_name,\n\u001b[1;32m   3335\u001b[0m        interactivity\u001b[38;5;241m=\u001b[39minteractivity, compiler\u001b[38;5;241m=\u001b[39mcompiler, result\u001b[38;5;241m=\u001b[39mresult)\n\u001b[1;32m   3337\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_execution_succeeded \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m has_raised\n",
      "File \u001b[0;32m~/miniconda3/envs/wotts/lib/python3.11/site-packages/IPython/core/interactiveshell.py:3517\u001b[0m, in \u001b[0;36mrun_ast_nodes\u001b[0;34m()\u001b[0m\n\u001b[1;32m   3516\u001b[0m     asy \u001b[38;5;241m=\u001b[39m compare(code)\n\u001b[0;32m-> 3517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_code(code, result, async_\u001b[38;5;241m=\u001b[39masy):\n\u001b[1;32m   3518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/wotts/lib/python3.11/site-packages/IPython/core/interactiveshell.py:3577\u001b[0m, in \u001b[0;36mrun_code\u001b[0;34m()\u001b[0m\n\u001b[1;32m   3576\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 3577\u001b[0m         exec(code_obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muser_global_ns, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muser_ns)\n\u001b[1;32m   3578\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   3579\u001b[0m     \u001b[38;5;66;03m# Reset our crash handler in place\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[55], line 51\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# Update state using the gradient\u001b[39;00m\n\u001b[0;32m---> 51\u001b[0m s \u001b[38;5;241m=\u001b[39m s \u001b[38;5;241m-\u001b[39m jax\u001b[38;5;241m.\u001b[39mgrad(model\u001b[38;5;241m.\u001b[39menergy)(s)  \u001b[38;5;66;03m# Compute gradient of the energy function\u001b[39;00m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m# Compute the energy at the new state\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[55], line 29\u001b[0m, in \u001b[0;36menergy\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Compute the second term\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m energy \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m jnp\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mnorm(s \u001b[38;5;241m-\u001b[39m rho_activation) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Debug print statements\u001b[39;00m\n",
      "\u001b[0;31mJaxStackTraceBeforeTransformation\u001b[0m: FloatingPointError: invalid value (nan) encountered in jit(norm). Because jax_config.debug_nans.value and/or config.jax_debug_infs is set, the de-optimized function (i.e., the function as if the `jit` decorator were removed) was called in an attempt to get a more precise error message. However, the de-optimized function did not produce invalid values during its execution. This behavior can result from `jit` optimizations causing the invalid value to be produced. It may also arise from having nan/inf constants as outputs, like `jax.jit(lambda ...: jax.numpy.nan)(...)`. \n\nIt may be possible to avoid the invalid value by removing the `jit` decorator, at the cost of losing optimizations. \n\nIf you see this error, consider opening a bug report at https://github.com/jax-ml/jax.\n\nThe preceding stack trace is the source of the JAX operation that, once transformed by JAX, triggered the following exception.\n\n--------------------",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mFloatingPointError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 51\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m40\u001b[39m)\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# Update state using the gradient\u001b[39;00m\n\u001b[0;32m---> 51\u001b[0m s \u001b[38;5;241m=\u001b[39m s \u001b[38;5;241m-\u001b[39m \u001b[43mjax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menergy\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Compute gradient of the energy function\u001b[39;00m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m# Compute the energy at the new state\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping hidden 16 frame]\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/wotts/lib/python3.11/site-packages/jax/_src/pjit.py:1719\u001b[0m, in \u001b[0;36m_pjit_call_impl_python\u001b[0;34m(jaxpr, in_shardings, out_shardings, in_layouts, out_layouts, resource_env, donated_invars, name, keep_unused, inline, compiler_options_kvs, *args)\u001b[0m\n\u001b[1;32m   1702\u001b[0m \u001b[38;5;66;03m# If control reaches this line, we got a NaN on the output of `compiled`\u001b[39;00m\n\u001b[1;32m   1703\u001b[0m \u001b[38;5;66;03m# but not `fun.call_wrapped` on the same arguments. Let's tell the user.\u001b[39;00m\n\u001b[1;32m   1704\u001b[0m msg \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Because \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1705\u001b[0m        \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjax_config.debug_nans.value and/or config.jax_debug_infs is set, the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1706\u001b[0m        \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mde-optimized function (i.e., the function as if the `jit` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1717\u001b[0m        \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf you see this error, consider opening a bug report at \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1718\u001b[0m        \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://github.com/jax-ml/jax.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1719\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFloatingPointError\u001b[39;00m(msg)\n",
      "\u001b[0;31mFloatingPointError\u001b[0m: invalid value (nan) encountered in jit(norm). Because jax_config.debug_nans.value and/or config.jax_debug_infs is set, the de-optimized function (i.e., the function as if the `jit` decorator were removed) was called in an attempt to get a more precise error message. However, the de-optimized function did not produce invalid values during its execution. This behavior can result from `jit` optimizations causing the invalid value to be produced. It may also arise from having nan/inf constants as outputs, like `jax.jit(lambda ...: jax.numpy.nan)(...)`. \n\nIt may be possible to avoid the invalid value by removing the `jit` decorator, at the cost of losing optimizations. \n\nIf you see this error, consider opening a bug report at https://github.com/jax-ml/jax."
     ]
    }
   ],
   "source": [
    "import typing as tp\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import equinox as eqx\n",
    "\n",
    "\n",
    "class FakeNetwork(eqx.Module):\n",
    "    def energy(self, s: jax.Array) -> jax.Array:\n",
    "        \"\"\"\n",
    "        Energy function for a single-layer, two-neuron network.\n",
    "        Args:\n",
    "            s: The concatenated state array (phi^0 and phi^1).\n",
    "        Returns:\n",
    "            The energy scalar value.\n",
    "        \"\"\"\n",
    "        # Compute the first term: ||phi^0||^2\n",
    "        energy = 0.5 * jnp.linalg.norm(s) ** 2\n",
    "        # energy = 0\n",
    "\n",
    "        # Compute the second term: ||phi^1 - tanh(W^0 * phi^0 + b^0)||^2\n",
    "        weighted_sum = jnp.dot(jnp.ones((2, 2)), jnp.ones((2,))) # W^0 * phi^0 + b^0\n",
    "        rho_activation = jax.nn.hard_sigmoid(weighted_sum)  # ρ(W^0 * phi^0 + b^0)\n",
    "\n",
    "        # Debug print statements\n",
    "        print(\"rho_activation:\", s)\n",
    "        print(\"s:\", s - rho_activation)\n",
    "\n",
    "        # Compute the second term\n",
    "        energy = 0.5 * jnp.linalg.norm(s - rho_activation) ** 2\n",
    "\n",
    "        # Debug print statements\n",
    "        print(\"Updated energy:\", energy)\n",
    "        return energy\n",
    "\n",
    "\n",
    "# Instantiate the model\n",
    "model = FakeNetwork()\n",
    "\n",
    "# Run the gradient descent loop\n",
    "with jax.debug_nans(True):\n",
    "    T = 100  # Number of iterations\n",
    "    s = jnp.array([4.0, 2.03])  # Initial state\n",
    "\n",
    "    for i in range(T):\n",
    "\n",
    "        print(f\"Iteration {i}, s: {s}\")\n",
    "        energy = model.energy(s)\n",
    "        print(f\"Energy at new state: {energy}\")\n",
    "        print(\"=\" * 40)\n",
    "        # Update state using the gradient\n",
    "        s = s - jax.grad(model.energy)(s)  # Compute gradient of the energy function\n",
    "\n",
    "        # Compute the energy at the new state\n"
   ]
  },
  {
   "attachments": {
    "CleanShot 2025-01-11 at 20.11.44@2x.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The primitive is defined as:\n",
    "\n",
    "![CleanShot 2025-01-11 at 20.11.44@2x.png](<attachment:CleanShot 2025-01-11 at 20.11.44@2x.png>)\n",
    "\n",
    "It's with this that we can calculate the next state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First batch shape (inputs): (1, 1, 28, 28)\n",
      "Number of labels in the first batch: 1\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import optax\n",
    "from typing import List, Tuple\n",
    "\n",
    "# Initialize random key\n",
    "key = jax.random.PRNGKey(42)\n",
    "num_epochs = 10\n",
    "batch_size= 1\n",
    "beta = 0.0000001 \n",
    "lr = 1\n",
    "energy_funciton = DeepEnergyConvNetwork(num_inputs=784, num_outputs=10, key=key)\n",
    "# Fetch and preprocess MNIST dataset\n",
    "x_train, y_train = fetch_MNIST()  # Assumes this function fetches training data\n",
    "x_train = jnp.where(x_train > 20, 1, 0)  # Binarize images\n",
    "x_train = jnp.array(x_train, dtype=jnp.float32)  # Convert to float32\n",
    "\n",
    "# Create batches\n",
    "num_samples = x_train.shape[0]\n",
    "batches: List[Tuple[jnp.ndarray, jnp.ndarray]] = [\n",
    "    (x_train[i:i + batch_size], y_train[i:i + batch_size])\n",
    "    for i in range(0, num_samples, batch_size)\n",
    "]\n",
    "\n",
    "# Print batch information for verification\n",
    "print(f\"First batch shape (inputs): {batches[0][0].shape}\")\n",
    "print(f\"Number of labels in the first batch: {len(batches[0][1])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "239.03735\n",
      "958.7101\n",
      "3514.6824\n",
      "8437.326\n",
      "13791.136\n",
      "18397.47\n",
      "22235.814\n",
      "25497.256\n",
      "28325.205\n",
      "30821.025\n",
      "33055.344\n",
      "35079.453\n",
      "36929.906\n",
      "38635.586\n",
      "40219.305\n",
      "41699.395\n",
      "43090.65\n",
      "44403.08\n",
      "45644.55\n",
      "46822.266\n",
      "47943.51\n",
      "49013.09\n",
      "50036.723\n",
      "51018.574\n",
      "51961.71\n",
      "52870.0\n",
      "53746.016\n",
      "54592.11\n",
      "55410.984\n",
      "56205.6\n",
      "56976.58\n",
      "57724.242\n",
      "58450.32\n",
      "59156.39\n",
      "59843.863\n",
      "60513.87\n",
      "61167.25\n",
      "61804.89\n",
      "62427.707\n",
      "63036.79\n",
      "63632.406\n",
      "64214.742\n",
      "64784.27\n",
      "65341.496\n",
      "65886.98\n",
      "66421.234\n",
      "66944.82\n",
      "67458.266\n",
      "67962.06\n",
      "68456.766\n",
      "68942.75\n",
      "69420.34\n",
      "69889.85\n",
      "70351.67\n",
      "70806.414\n",
      "71254.445\n",
      "71695.43\n",
      "72129.32\n",
      "72556.414\n",
      "72976.93\n",
      "73391.13\n",
      "73799.22\n",
      "74201.35\n",
      "74597.75\n",
      "74988.57\n",
      "75373.984\n",
      "75754.14\n",
      "76129.27\n",
      "76499.58\n",
      "76865.37\n",
      "77226.8\n",
      "77583.7\n",
      "77936.28\n",
      "78284.664\n",
      "78629.01\n",
      "78969.37\n",
      "79305.73\n",
      "79638.17\n",
      "79966.87\n",
      "80291.9\n",
      "80613.41\n",
      "80931.47\n",
      "81246.195\n",
      "81557.65\n",
      "81865.84\n",
      "82170.86\n",
      "82472.695\n",
      "82771.375\n",
      "83067.0\n",
      "83359.62\n",
      "83649.32\n",
      "83936.16\n",
      "84220.22\n",
      "84501.56\n",
      "84780.234\n",
      "85056.336\n",
      "85329.91\n",
      "85601.03\n",
      "85869.77\n",
      "86136.234\n",
      "86400.58\n",
      "86662.9\n",
      "86923.21\n",
      "87181.414\n",
      "87437.43\n",
      "87691.234\n",
      "87942.89\n",
      "88192.414\n",
      "88439.86\n",
      "88685.28\n",
      "88928.78\n",
      "89170.5\n",
      "89410.58\n",
      "89649.18\n",
      "89886.49\n",
      "90122.375\n",
      "90356.53\n",
      "90588.84\n",
      "90819.336\n",
      "91048.04\n",
      "91274.97\n",
      "91500.21\n",
      "91723.78\n",
      "91945.805\n",
      "92166.43\n",
      "92385.664\n",
      "92603.44\n",
      "92819.64\n",
      "93034.35\n",
      "93247.625\n",
      "93459.516\n",
      "93670.05\n",
      "93879.19\n",
      "94086.94\n",
      "94293.36\n",
      "94498.38\n",
      "94702.05\n",
      "94904.445\n",
      "95105.6\n",
      "95305.68\n",
      "95504.64\n",
      "95702.42\n",
      "95898.92\n",
      "96094.21\n",
      "96288.29\n",
      "96481.18\n",
      "96672.88\n",
      "96863.4\n",
      "97052.78\n",
      "97240.99\n",
      "97428.05\n",
      "97613.98\n",
      "97798.76\n",
      "97982.46\n",
      "98165.15\n",
      "98346.94\n",
      "98527.984\n",
      "98708.195\n",
      "98887.375\n",
      "99065.516\n",
      "99242.66\n",
      "99418.836\n",
      "99594.04\n",
      "99768.29\n",
      "99941.58\n",
      "100113.945\n",
      "100285.375\n",
      "100455.94\n",
      "100625.67\n",
      "100794.72\n",
      "100963.06\n",
      "101130.51\n",
      "101296.96\n",
      "101462.484\n",
      "101627.08\n",
      "101790.8\n",
      "101953.664\n",
      "102115.7\n",
      "102276.92\n",
      "102437.36\n",
      "102596.96\n",
      "102755.76\n",
      "102913.77\n",
      "103071.01\n",
      "103227.48\n",
      "103383.18\n",
      "103538.164\n",
      "103692.43\n",
      "103845.984\n",
      "103998.86\n",
      "104151.06\n",
      "104302.586\n",
      "104453.42\n",
      "104603.54\n",
      "104752.98\n",
      "104901.73\n",
      "105049.766\n",
      "105197.16\n",
      "105343.84\n",
      "105489.87\n",
      "105635.22\n",
      "105779.92\n",
      "105923.97\n",
      "106067.375\n",
      "106210.164\n",
      "106352.336\n",
      "106493.9\n",
      "106634.84\n",
      "106775.2\n",
      "106915.02\n",
      "107054.305\n",
      "107193.05\n",
      "107331.27\n",
      "107468.97\n",
      "107606.13\n",
      "107742.73\n",
      "107878.78\n",
      "108014.3\n",
      "108149.29\n",
      "108283.805\n",
      "108417.87\n",
      "108551.49\n",
      "108684.65\n",
      "108817.305\n",
      "108949.42\n",
      "109081.01\n",
      "109212.05\n",
      "109342.58\n",
      "109472.516\n",
      "109601.98\n",
      "109730.88\n",
      "109859.27\n",
      "109987.17\n",
      "110114.555\n",
      "110241.43\n",
      "110367.8\n",
      "110493.66\n",
      "110619.016\n",
      "110743.87\n",
      "110868.21\n",
      "110992.07\n",
      "111115.42\n",
      "111238.29\n",
      "111360.69\n",
      "111482.6\n",
      "111604.03\n",
      "111725.04\n",
      "111845.57\n",
      "111965.66\n",
      "112085.3\n",
      "112204.516\n",
      "112323.3\n",
      "112441.65\n",
      "112559.56\n",
      "112677.06\n",
      "112794.16\n",
      "112910.81\n",
      "113027.055\n",
      "113142.88\n",
      "113258.32\n",
      "113373.336\n",
      "113487.984\n",
      "113602.24\n",
      "113716.12\n",
      "113829.6\n",
      "113942.72\n",
      "114055.45\n",
      "114167.78\n",
      "114279.766\n",
      "114391.34\n",
      "114502.61\n",
      "114613.49\n",
      "114724.01\n",
      "114834.164\n",
      "114943.945\n",
      "115053.38\n",
      "115162.48\n",
      "115271.19\n",
      "115379.55\n",
      "115487.586\n",
      "115595.25\n",
      "115702.61\n",
      "115809.63\n",
      "115916.3\n",
      "116022.67\n",
      "116128.734\n",
      "116234.51\n",
      "116339.96\n",
      "116445.086\n",
      "116549.914\n",
      "116654.445\n",
      "116758.65\n",
      "116862.516\n",
      "116966.13\n",
      "117069.4\n",
      "117172.414\n",
      "117275.07\n",
      "117377.45\n",
      "117479.54\n",
      "117581.3\n",
      "------------------------------\n",
      "117682.75\n",
      "3\n",
      "117783.93\n",
      "3\n",
      "117884.81\n",
      "3\n",
      "117985.42\n",
      "3\n",
      "118085.734\n",
      "3\n",
      "118185.73\n",
      "3\n",
      "118285.44\n",
      "3\n",
      "118384.88\n",
      "3\n",
      "118484.03\n",
      "3\n",
      "118582.88\n",
      "3\n",
      "118681.47\n",
      "3\n",
      "118779.766\n",
      "3\n",
      "118877.8\n",
      "3\n",
      "118975.55\n",
      "3\n",
      "119073.04\n",
      "3\n",
      "119170.24\n",
      "3\n",
      "119267.19\n",
      "3\n",
      "119363.87\n",
      "3\n",
      "119460.26\n",
      "3\n",
      "119556.39\n",
      "3\n",
      "119652.29\n",
      "3\n",
      "119747.9\n",
      "3\n",
      "119843.26\n",
      "3\n",
      "119938.35\n",
      "3\n",
      "120033.19\n",
      "3\n",
      "120127.79\n",
      "3\n",
      "120222.125\n",
      "3\n",
      "120316.21\n",
      "3\n",
      "120410.08\n",
      "3\n",
      "120503.695\n",
      "3\n",
      "120597.07\n",
      "3\n",
      "120690.21\n",
      "3\n",
      "120783.125\n",
      "3\n",
      "120875.82\n",
      "3\n",
      "120968.27\n",
      "3\n",
      "121060.51\n",
      "3\n",
      "121152.53\n",
      "3\n",
      "121244.33\n",
      "3\n",
      "121335.93\n",
      "3\n",
      "121427.29\n",
      "3\n",
      "4.14199e+17\n",
      "5.596561e+21\n",
      "5.597446e+21\n",
      "5.597446e+21\n",
      "5.597446e+21\n",
      "5.597446e+21\n",
      "5.597446e+21\n",
      "5.597446e+21\n",
      "5.597446e+21\n",
      "5.597446e+21\n",
      "5.597446e+21\n",
      "5.597446e+21\n",
      "5.597446e+21\n",
      "5.597446e+21\n",
      "5.597446e+21\n",
      "5.597446e+21\n",
      "5.597446e+21\n",
      "5.597446e+21\n",
      "5.597446e+21\n",
      "5.597446e+21\n",
      "5.597446e+21\n",
      "5.597446e+21\n",
      "5.597446e+21\n",
      "5.597446e+21\n",
      "5.597446e+21\n",
      "5.597446e+21\n",
      "5.597446e+21\n",
      "5.597446e+21\n",
      "5.597446e+21\n",
      "5.597446e+21\n",
      "5.597446e+21\n",
      "5.597446e+21\n",
      "5.597446e+21\n",
      "5.597446e+21\n",
      "5.597446e+21\n",
      "5.597446e+21\n",
      "5.597446e+21\n",
      "5.597446e+21\n",
      "5.597446e+21\n",
      "5.597446e+21\n",
      "5.597446e+21\n",
      "5.597446e+21\n",
      "5.597446e+21\n",
      "5.597446e+21\n",
      "5.597446e+21\n",
      "5.597446e+21\n",
      "5.597446e+21\n",
      "5.597446e+21\n",
      "5.597446e+21\n",
      "5.597446e+21\n",
      "5.597446e+21\n",
      "5.597446e+21\n",
      "5.597446e+21\n",
      "5.597446e+21\n",
      "5.597446e+21\n",
      "5.597446e+21\n",
      "5.597446e+21\n",
      "5.597446e+21\n",
      "5.597446e+21\n",
      "5.597446e+21\n",
      "5.597446e+21\n",
      "5.597446e+21\n",
      "5.597446e+21\n",
      "5.597446e+21\n",
      "5.597446e+21\n",
      "5.597446e+21\n",
      "5.597446e+21\n",
      "5.597446e+21\n",
      "5.597446e+21\n",
      "5.597446e+21\n",
      "5.597446e+21\n",
      "5.597446e+21\n",
      "5.597446e+21\n",
      "5.597446e+21\n",
      "5.597446e+21\n",
      "5.597446e+21\n",
      "5.597446e+21\n",
      "5.597446e+21\n",
      "5.597446e+21\n",
      "5.597446e+21\n",
      "5.597446e+21\n",
      "5.597446e+21\n",
      "5.597446e+21\n",
      "5.597446e+21\n",
      "5.597446e+21\n",
      "5.597446e+21\n",
      "5.597446e+21\n",
      "5.597446e+21\n",
      "5.597446e+21\n",
      "5.597446e+21\n",
      "5.597446e+21\n",
      "5.597446e+21\n",
      "5.597446e+21\n",
      "5.597446e+21\n",
      "5.597446e+21\n",
      "5.597446e+21\n",
      "5.597446e+21\n",
      "5.597446e+21\n",
      "5.597446e+21\n",
      "5.597446e+21\n",
      "5.597446e+21\n",
      "5.597446e+21\n",
      "5.597446e+21\n",
      "5.597446e+21\n",
      "5.597446e+21\n",
      "5.597446e+21\n",
      "5.597446e+21\n",
      "5.597446e+21\n",
      "5.597446e+21\n",
      "5.597446e+21\n",
      "5.597446e+21\n",
      "5.597446e+21\n",
      "5.597446e+21\n",
      "5.597446e+21\n",
      "5.597446e+21\n",
      "5.597446e+21\n",
      "5.597446e+21\n",
      "5.597446e+21\n",
      "5.597446e+21\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[140], line 31\u001b[0m\n\u001b[1;32m     29\u001b[0m     state \u001b[38;5;241m=\u001b[39m lr\u001b[38;5;241m*\u001b[39mjax\u001b[38;5;241m.\u001b[39mgrad(energy_funciton\u001b[38;5;241m.\u001b[39mprimitive)(state)\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;66;03m# print(state)\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m     \u001b[38;5;28mprint\u001b[39m(energy_funciton\u001b[38;5;241m.\u001b[39mprimitive(state))\n\u001b[1;32m     33\u001b[0m beta_state \u001b[38;5;241m=\u001b[39m state\n\u001b[1;32m     34\u001b[0m layers \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/wotts/lib/python3.11/site-packages/jax/_src/array.py:285\u001b[0m, in \u001b[0;36mArrayImpl.__str__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__str__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 285\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_value\u001b[49m)\n",
      "File \u001b[0;32m~/miniconda3/envs/wotts/lib/python3.11/site-packages/jax/_src/profiler.py:333\u001b[0m, in \u001b[0;36mannotate_function.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m    331\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    332\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m TraceAnnotation(name, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdecorator_kwargs):\n\u001b[0;32m--> 333\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    334\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m wrapper\n",
      "File \u001b[0;32m~/miniconda3/envs/wotts/lib/python3.11/site-packages/jax/_src/array.py:629\u001b[0m, in \u001b[0;36mArrayImpl._value\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_npy_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_fully_replicated:\n\u001b[0;32m--> 629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_npy_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_single_device_array_to_np_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_npy_value\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mwriteable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    631\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(np\u001b[38;5;241m.\u001b[39mndarray, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_npy_value)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "def step(energy_funciton, beta_state_t, beta_state_t_1):\n",
    "    layers = []\n",
    "    def update_weights(p, x):\n",
    "        path = jax.tree_util.keystr(p).split(\"[\")\n",
    "        if path[0] == \".layers\":\n",
    "            layer = int(path[1][0])\n",
    "            calc = (1/beta)*(jnp.outer(jax.nn.tanh(beta_state_t_1[layer]), jax.nn.tanh(beta_state_t_1[layer + 1]).T) - jnp.outer(jax.nn.tanh(beta_state_t[layer]), jax.nn.tanh(beta_state_t[layer + 1]).T)).T\n",
    "            # print(x.shape)\n",
    "            # print(calc.shape)\n",
    "\n",
    "            layers.append(calc)\n",
    "            return x\n",
    "        return x\n",
    "\n",
    "    jax.tree_util.tree_map_with_path(update_weights, energy_funciton)\n",
    "    return layers\n",
    "    \n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs): \n",
    "    for x, y  in zip(x_train, y_train):\n",
    "        \n",
    "        k, key = jax.random.split(key)\n",
    "        # print(y_train)\n",
    "        y = jax.nn.one_hot(y_train, 10)\n",
    "        state = jnp.zeros(shape=(4*784 + 16*784 + 10))\n",
    "        state = jnp.concat([jnp.reshape(x, (784,)), state])\n",
    "        for i in range(0, 300):\n",
    "            state = lr*jax.grad(energy_funciton.primitive)(state)\n",
    "            # print(state)\n",
    "            print(energy_funciton.primitive(state))\n",
    "\n",
    "        beta_state = state\n",
    "        layers = [0,0,0,0]\n",
    "        for i in range(0, 40):\n",
    "            beta_state_t = jnp.split(beta_state, [784, 784 + 4*784, 784 + 4*784+ 16*784])\n",
    "\n",
    "            def hmm(s):\n",
    "                s_3 = jnp.split(beta_state, [784 + 4*784+ 16*784])[1]\n",
    "                return energy_funciton.primitive(s) - beta * jnp.mean((s_3 - y)**2)\n",
    "            \n",
    "            beta_state = lr*jax.grad(hmm)(beta_state)\n",
    "\n",
    "            if i == 0:\n",
    "                print(\"-\"*30)\n",
    "            print(energy_funciton.primitive(beta_state))\n",
    "\n",
    "\n",
    "            beta_state_t_1 = jnp.split(beta_state, [784, 784 + 4*784, 784 + 4*784+ 16*784])\n",
    "            print(len(step(energy_funciton, beta_state_t, beta_state_t_1)))\n",
    "            for i, layer in enumerate(step(energy_funciton, beta_state_t, beta_state_t_1)):\n",
    "                \n",
    "                layers[i] += layer\n",
    "               \n",
    "        def update_weights(p, x):\n",
    "            path = jax.tree_util.keystr(p).split(\"[\")\n",
    "            if path[0] == \".layers\":\n",
    "                layer = int(path[1][0])\n",
    "                return layers[layer]\n",
    "            return x\n",
    "\n",
    "        energy_funciton = jax.tree_util.tree_map_with_path(update_weights, energy_funciton)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think I need to be more simple before building on more complicated problems. Let's start with a super simple one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wotts",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
